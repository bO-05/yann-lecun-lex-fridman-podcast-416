import { Callout, Steps, Step } from "nextra-theme-docs";

# Regulation and Safety

As AI systems become more advanced and ubiquitous, the question of regulation and safety becomes increasingly important. Yann LeCun, Chief AI Scientist at Meta, believes that the focus should be on making better, safer AI systems rather than restricting access to the technology.

## Building Safe AI Systems

Creating safe AI systems is not a simple task that can be solved with a single, silver-bullet solution. Instead, it requires a progressive, iterative design process where guard rails are put in place to ensure proper behavior. This process is similar to the development of other complex systems, such as turbojet engines, which have become incredibly reliable through decades of fine-tuning and improvement.

<Callout emoji="ðŸ’¡">
The proper way to ensure AI safety is not through specific provisions, but by making better AI systems. A more reliable AI system is also a safer one.
</Callout>

## Adjusting World Models and Objective Functions

When an AI system operates in the real world, there are two main ways it can be wrong:

1. The objective function does not reflect the actual objective we want to optimize.
2. The world model is inaccurate, leading to incorrect predictions.

In these cases, reinforcement learning can be used to adjust the world model or the objective function. This allows the AI system to explore parts of the state space where the world model is known to be inaccurate, enabling it to improve its understanding of the environment without causing harm.

## Progressive Development and Deployment

LeCun emphasizes that the development of advanced AI systems will be a gradual process, not a sudden event. As AI becomes more sophisticated, we will have the opportunity to put guard rails in place and learn how to control these systems effectively.

<Steps>
### Step 1

Develop AI systems with capabilities similar to simple animals, such as cats or parrots.

### Step 2

As AI becomes more advanced, implement guard rails and control mechanisms to ensure safe behavior.

### Step 3

Continue to refine and improve AI systems, gradually increasing their intelligence while maintaining safety and control.
</Steps>

By following this progressive approach, we can mitigate the risks associated with advanced AI systems and ensure that they are developed and deployed in a responsible manner.

## Addressing Concerns About AI Misuse

Some people worry that advanced AI systems could be used maliciously, such as for creating convincing propaganda or influencing elections. However, LeCun argues that in a future where AI assistants mediate our interactions with the digital world, these concerns can be largely mitigated.

<Callout emoji="ðŸ›¡ï¸">
Your AI assistant will be just as smart as any potentially malicious AI system, acting as a filter to protect you from harmful content or attempts at manipulation.
</Callout>

For more information on the importance of open source AI platforms in promoting diversity and preventing the concentration of power, see the [Open Source AI and Regulation](/open-source-ai-regulation) section.