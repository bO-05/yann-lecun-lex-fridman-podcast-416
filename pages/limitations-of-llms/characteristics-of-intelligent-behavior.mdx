import { Callout, Steps, Step } from "nextra-theme-docs";

# Characteristics of Intelligent Behavior

According to Yann LeCun, large language models (LLMs) lack several essential characteristics of intelligent behavior, which prevents them from being the path to superhuman intelligence. These characteristics include:

- The capacity to understand the physical world
- The ability to remember and retrieve information
- The ability to reason
- The ability to plan

LeCun argues that LLMs can only perform these tasks in a very primitive way, if at all. This limitation stems from the fact that most of our knowledge and understanding of the world comes from observation and interaction with the physical environment, rather than from language alone.

## Understanding the Physical World

To truly understand the physical world, an AI system must be able to learn from sensory input, such as vision, touch, and audio. This type of learning is much richer in information compared to learning from text alone. LeCun provides a striking comparison:

<Callout emoji="ðŸ’¡">
A four-year-old child has been awake for approximately 16,000 hours, and the amount of visual information that has reached their visual cortex is about 10^15 bytes. In contrast, LLMs are typically trained on around 10^13 tokens, which is equivalent to about 2 * 10^13 bytes â€“ roughly 170,000 years worth of reading for a human.
</Callout>

Despite the seemingly large amount of data used to train LLMs, it pales in comparison to the information a child receives through sensory input in just a few years. This highlights the importance of learning from the physical world to develop a true understanding of it.

## Memory, Reasoning, and Planning

In addition to understanding the physical world, intelligent behavior requires the ability to remember and retrieve information, reason about it, and plan accordingly. LLMs struggle with these tasks because they are primarily trained to predict the next word in a sequence based on the words that come before it.

This autoregressive prediction process does not allow for the kind of reasoning and planning that humans engage in when solving problems or completing tasks. Human thought processes involve creating mental models and manipulating them to imagine the outcomes of different actions â€“ something that LLMs cannot currently do.

To achieve intelligent behavior, AI systems need to be able to learn abstract representations of the world and use these representations for reasoning and planning. This is where [joint embedding architectures](/joint-embedding-architectures) come into play, as they aim to learn these abstract representations from sensory data.

By focusing on learning from the physical world and developing the ability to reason and plan using abstract representations, AI researchers can work towards creating systems that exhibit the essential characteristics of intelligent behavior. Only then can we hope to achieve superhuman intelligence.