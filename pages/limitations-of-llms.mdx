import { Callout, Steps, Step } from "nextra-theme-docs";

# Limitations of LLMs

Yann LeCun, the Chief AI Scientist at Meta, argues that autoregressive large language models (LLMs) are not the path to achieving superhuman intelligence. While LLMs have demonstrated impressive capabilities in natural language processing tasks, they have several fundamental limitations that prevent them from reaching human-level intelligence.

## Characteristics of Intelligent Behavior

LLMs lack several key characteristics of intelligent behavior, such as the ability to understand the physical world, remember and retrieve information, reason, and plan. These limitations are discussed in more detail in the [Characteristics of Intelligent Behavior](/limitations-of-llms/characteristics-of-intelligent-behavior) subsection.

## Importance of Sensory Input

LeCun emphasizes that most knowledge is derived from observation and interaction with the real world, rather than language alone. Sensory input, particularly visual data, provides a much richer source of information for learning than text-based data. This concept is further explored in the [Importance of Sensory Input](/limitations-of-llms/importance-of-sensory-input) subsection.

<Callout emoji="ðŸ’¡">
  LLMs are trained on vast amounts of text data, but this represents only a fraction of the information humans learn from sensory input during their early years of life.
</Callout>

LeCun argues that while LLMs can be fine-tuned to perform well on specific tasks, they lack the grounding in reality necessary for developing a comprehensive understanding of the world. This limitation prevents them from achieving human-like reasoning and planning capabilities.

To illustrate the difference in information content between sensory input and language, consider the following comparison:

- A four-year-old child has been exposed to approximately 10^15 bytes of visual information during their 16,000 waking hours.
- In contrast, LLMs are typically trained on around 10^13 tokens, with each token representing about 2 bytes of data. This is equivalent to the amount of information a human would encounter by reading for 170,000 years at 8 hours per day.

Despite the seemingly large amount of data used to train LLMs, it pales in comparison to the rich sensory information humans process in their early years. This difference in information content and quality is a significant factor in the limitations of LLMs.

In conclusion, while LLMs have made significant strides in natural language processing, their lack of grounding in the physical world and reliance on text-based data limit their ability to achieve human-like intelligence. LeCun suggests that alternative approaches, such as [Joint Embedding Architectures](/joint-embedding-architectures), may be more promising for developing AI systems with a deeper understanding of the world.